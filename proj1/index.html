<html>
	<head>
	</head>
	<body>
		<h1> Project 1 </h1>
		<p>Overview:<br>
		   At a high level, this project introduced ways to draw images to the screen, and then gradually added new techniques to be used to antialias. <br>
		   We started out with implementing the most basic triangle rasterization by taking mid pixel samples and categorizing them as within a given triangle or not. <br>
		   Immediately after that, we added supersampling which conceptually just samples more at finer points in order address the jaggies from the previous implementation. <br>
		   Task 3 wasn't incredibly related to the other tasks in the project, but it gave a look at how models are constructed in an SVG file and specifically gave a better <br>
		   understanding of the hierarchical construction of the model. Task 4 required implementing barycentric interpolation to interpolate the colors within triangles by <br>
		   the colors of the vertices. Then, using that as a foundation, task 5 required barycentric interpolation in order to map positions in screen space to appropriate <br>
		   locations in texture space in order to sample those textures to project onto the screen space. Task 6 then further builds on this by introducing level mapping with mipmaps <br>
		   for the textures to address aliasing in the previous texture mapping. It was interesting to build basic solutions, notice potential issues or further applications for those <br>
		   solutions, and then further adding things to either try to address those issues or to build upon the simpler implementations to do more. 
		   
		</p>
		<p></p>
		<p> Task1:<br>
		    To rasterize triangles, we sample points on the screen space to see whether that point is within the triangle that is being rasterized. <br>
		    If the point is within the triangle, the pixel corresponding to that point on the frame buffer will be colored in.<br>
	 	    <br>
		    The algorithm I used does this by finding the minimum and maximum x and y coordinates between all the vertices of the triangle, rounding down <br>
		    on the minimum and rounding up on the maximum. This establishes a box that covers the entire triangle. Then, it iterates over all the points in the box, <br>
		    sampling at half integer coordinates in screen space. To check whether the sample is within the triangle, the algorithm checks if the sample point <br>
		    is inside of each of the three lines comprising the edges of the triangle, counting the point as inside the triangle if it is inside all three lines. <br>
		    However, the line equation can result in either values > 0 or < 0 being considered within the triangle depending on whether we define the lines going <br>
		    counterclockwise around the vertices or clockwise around the vertices. Since the function doesn't check what direction the lines are formed through, the <br>
		    algorithm instead checks that all of the line calculations end up greater than or equal to 0, or less than or equal to 0. This way, points within the triangle <br>
		    are marked as such regardless of which direction the vertices were chosen. Finally, if the point is determined to be in the triangle, the corresponding pixel <br>
		    is filled in the framebuffer.<br>
		    <br>
		    This algorithm is the one that checks each sample within the bounding box of the triangle, so for obvious reasons it can't be worse than itself. 
		</p>
		<img src="proj1task1.png" alt="Task 1 Test 4 screenshot">
		<p></p>
		<p> Task2:<br>
		    The supersampling algorithm works by iterating through the box bounding the triangle as was done in Task 1, but instead of only sampling the midpoint of <br>
	            the pixels, it divides each sampled pixel area into N even squares, where N is the sampling rate, and then sampling at the midpoint of each of these squares. <br>
		    Since the sample rate is restricted to be either 1, 4, 9, or 16, we ignore the case where the sampled area can't be split up into even squares. The sample buffer <br>
	            now needs to hold N samples for each pixel on the framebuffer, so it is resized to hold a factor N more or less entries whenever the sample rate is changed. <br>
		    In addition, the fill pixel function now takes in another parameter which is sample, so that in the case of supersampling, N samples are stored at each corresponding <br>
	            x, y coordinate in the sample buffer. For line and point rasterization, the one taken sample for each point is stored in all N entries for that point, which will average <br>
	            out to be equivalent to doing one sample for line and point rasterization when it is resolved to the framebuffer. The resolve_to_framebuffer function takes the N samples <br>
		    for each pixel in the framebuffer and we average their colors out by summing every one of their R, G, and B channels individually, and then dividing them by N. <br>
		    Finally, it puts that averaged color onto the framebuffer. <br>
		    <br>
		    Supersampling is useful because it can be used for antialiasing. We antialiased here using supersampling and then downsampling, which effectively works as if we <br>
		    convolved the image by a 1 pixel box blur and then sampled. In both cases, the high frequency changes of the image are attenuated, reducing the amount of aliasing. <br>
		    <br>
		</p>
		<img src="test4sample1.png" alt="Task 2 Test 4 1 sample">
		<p> With no supersampling, we observe jaggies when at the edges of the triangle where we quickly change from a filled pixel to an empty pixel </p>
		<img src="test4sample2.png" alt="Task 2 Test 4 4 sample">
		<p> With a sample rate a 4, some of the pixels that were on the boundaries of the triangle and were colored either fully or not at all are now averaged to intermediate <br>
		    colors. Thus, the higher frequency changes are slightly attenuated, reducing the aliasing. </p>
		<img src="test4sample4.png" alt="Task 2 Test 4 16 sample">
		<p> This has a sample rate of 16, so the effects are essentially the same as the 4 sample case, but with more accuracy and lowering the high frequency changes further. </p>
		<p></p>
		<p> Task3:<br>
		</p>
		<img src="my_robot.png" alt="my robot">
		<p> The robot is supposed to be waving, with its left arm to its side and its right arm in the air, with a slight head tilt towards its left. </p> 
		<p></p>
		<p> Task4:<br>
		    Barycentric coordinates is a coordinate system for triangles that essentially introduces a weighting for each vertex of the triangle that changes depending on <br>
		    a point's distance from each vertex. These weights allow you to interpolate values within the triangle from just the vertices. As an example, when we make a colortri <br>
		    where there is one solid red, green, and blue vertex, we use barycentric coordinates to interpolate the colors within the triangle. The areas closer to the red vertex are more red, <br>
		    the areas closer to the green vertex are more green, and the areas closer to the blue vertex are more blue. When moving away from one of the vertex, the "color weight" from that <br>
                    vertex becomes smaller, while the weight of the vertices being approached increase, increasing the value of those vertices' colors at the new point.
		</p>
		<img src="colortri.png" alt="colortri">
		<p></p>
		<img src="test7.png" alt="test7">
		<p></p>
		<p> Task5:<br>
		    Pixel sampling is applying textures to a screen space pixel by mapping the screen space coordinate to the appropriate coordinate in texture space, getting a sample at that coordinate, <br>
		    and assigning that to the original pixel in screen space. In task 5, this was implemented by using barycentric interpolation at each sample point to find the corresponding coordinate <br>
		    in textures space through weighting the given vertices of the texture space mapped triangle. Once that coordinate was gotten, the pixel sampling could be done with either nearest pixel, <br>
	            which simply samples the nearest pixel in texture space to the u, v coordinate and uses that to color the original screen space pixel, or with bilinear sampling which essentially interpolates <br>
		    using the four nearest texture pixels with linear interpolations.
		</p>
		<p></p>
		<img src="task5nearestSample1.png" alt="nearest pixel, 1 sample">
		<p></p>
		<img src="task5bilinearSample1.png" alt="bilinear interp, 1 sample">
		<p> Here we see that with bilinear sampling, there are significantly less jaggies and the line is drawn smoother.</p>
		<img src="task5nearestSample16.png" alt="nearest pixel, 16 samples">
		<p></p>
		<img src="task5bilinearSample16.png" alt="bilinear interp, 16 samples">
		<p> With supersampling, the differences between the two sampling methods is very minor. </p>
		<p> There will be a large difference between the two sampling methods when are high frequency changes between sampled pixels in the texture space. <br>
		    The bilinear sampling will serve to average out the pixel values, attenuating the high frequency changes while nearest pixel sampling will have aliasing. <br>
		    With supersampling, since we're already attenuating high frequencies, the two sampling methods become similar in their results. However, it is important to note <br>
		    that bilinear sampling for antialiasing is much quicker than supersampling with high numbers of samples.
		</p>
		<p></p>
		<p> Task6:<br>
		    Level sampling approximates the frequency at the screen space coordinate, and uses that approximation in order to choose a mipmap level to sample from. <br>
		    Higher frequencies will require higher mipmap levels, which would entail a downsampled, lower resolution texture map. By doing this, low frequency spaces <br>
		    can maintain high resolution sampling, while high frequency spaces can be antialiased with the lower resolution blurring. In this project, I implemented it <br>
		    by using barycentric interpolation to find the coordinates that map the screen space coordinates (x, y), (x+1, y), and (x, y+1) to texture space. With these, <br>
		    we could find the rate of change of the texture space coordinates with respect to the x and y coordinates, and with these, we could use the formulas from lecture <br>
		    to calculate the appropriate mipmap level. Sampling as done in task 5 is then just repeated, though sampling from the appropriate mipmap level. The texture <br>
		    sampling could be done with either the mipmap level closest to the calculated level, or by doing an interpolation between the levels that are one above and <br>
		    one below the calculated level.
		</p>
		<p> Pixel sampling with bilinear interpolation provides decent antialiasing by doing a weighted average across the nearpy pixels in the texture space, attenuating <br>
		    the higher frequencies. The memory use isn't more than just the stored texture, though the speed is lowered by the three linear interpolations needed per pixel. <br>
		    Level sampling also provides antialiasing benefits by matching low frequency areas with high resolution textures and high frequency areas with low resolution textures. <br>
		    The speed is slowed by the overhead of calculating the mipmap level which at a glance seems to require more operations than the bilinear interpolation. The memory required <br>
		    is 33% more than that of just the texture alone as extra space is needed for the higher mipmap levels. <br>
		    Supersampling works well to provide high quality, but it costs a lot as it increases the amount of memory required and the number of operations made by a factor equal <br>
	            to the number of extra samples. 
		</p>
		<img src="lzero_pnearest.png" alt="L_ZERO, P_NEAREST">
		<p>L_ZERO, P_NEAREST</p>
		<img src="lzero_plinear.png" alt="L_ZERO, P_LINEAR">
		<p>L_ZERO, P_LINEAR</p>
		<img src="lnearest_pnearest.png" alt="L_NEAREST, P_NEAREST">
		<p>L_NEAREST, P_NEAREST</p>
		<img src="lnearest_plinear.png" alt="L_NEAREST, P_LINEAR">
		<p>L_NEAREST, P_LINEAR</p>
	</body>
</html>
